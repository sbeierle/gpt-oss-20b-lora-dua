from transformers import AutoTokenizer

print("ğŸ”„ Loading AutoTokenizer...")
tokenizer = AutoTokenizer.from_pretrained(
    "/workspace/gpt-oss-20b",
    use_fast=False  # âš¡ force slow mode
)

text = "As-salamu alaykum, this is a tokenizer test."
tokens = tokenizer.encode(text)
print("ğŸ”‘ Tokens:", tokens)
print("ğŸ“ Decoded back:", tokenizer.decode(tokens))
